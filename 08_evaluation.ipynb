{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35536f6-166c-4b89-8136-96417db5be30",
   "metadata": {
    "id": "b35536f6-166c-4b89-8136-96417db5be30"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8ac2e-eb68-4b84-85fe-3a6661eba976",
   "metadata": {
    "id": "77c8ac2e-eb68-4b84-85fe-3a6661eba976"
   },
   "source": [
    "<br>\n",
    "\n",
    "# <font color=\"#76b900\">**Notebook 8 [Assessment]:** RAG Evaluation</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "Welcome to the last notebook of the course! In the previous notebook, you integrated a vector store solution into a RAG pipeline! In this notebook, you will take that same pipeline and evaluate it using numerical RAG evaluation techniques incorporating LLM-as-a-Judge metrics!\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Learning Objectives:**\n",
    "\n",
    "- Learn how to integrate the techniques from prior notebooks to numerically approximate the goodness of your RAG pipeline.\n",
    "\n",
    "- **Final Exercice**: ***By working through this notebook in the Course Environment,* you will be able to submit the coding component of the course!**\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Questions To Think About:**\n",
    "\n",
    "- As you go along, remember what our metrics actually represent. Should our pipeline pass these objectives? Is our judge LLM sufficient for evaluating the pipeline? Does a particular metric even matter for our use case?\n",
    "- If we left the vectorstore-as-a-memory component in our chain, do you think it would still pass the evaluation? Additionally, is the evaluation useful for assessing vectorstore-as-a-memory performance? \n",
    "\n",
    "<br>\n",
    "\n",
    "### **Environment Setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "w_A3rZOrIeQD",
   "metadata": {
    "id": "w_A3rZOrIeQD"
   },
   "outputs": [],
   "source": [
    "# %pip install -q langchain langchain-nvidia-ai-endpoints gradio rich\n",
    "# %pip install -q arxiv pymupdf faiss-cpu ragas\n",
    "\n",
    "## If you encounter a typing-extensions issue, restart your runtime and try again\n",
    "# from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "# ChatNVIDIA.get_available_models()\n",
    "\n",
    "from functools import partial\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "norm_style = Style(bold=True)\n",
    "pprint = partial(console.print, style=base_style)\n",
    "pprint2 = partial(console.print, style=norm_style)\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "\n",
    "# ChatNVIDIA.get_available_models(base_url=\"http://llm_client:9000/v1\")\n",
    "instruct_llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zEgV11oZmJGg",
   "metadata": {
    "id": "zEgV11oZmJGg"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 1:** Pre-Release Evaluation\n",
    "\n",
    "In our previous notebook, we successfully combined several concepts to create a document chatbot with the aim of responsive and informative interactions. However, the diversity of user interactions necessitates comprehensive testing to truly understand the chatbot's performance. Thorough testing in varied scenarios is crucial to ensure that the system is not only robust and versatile but also aligns with user and provider expectations.\n",
    "\n",
    "After defining your chatbot's roles and implementing the necessary features, evaluating it becomes a multi-stage process:\n",
    "\n",
    "- **Typical Use Inspection:** Start by testing scenarios most relevant to your use case. See if your chatbot can reliably navigate discussions with limited human intervention.\n",
    "\n",
    "    - Additionally, identify limitations or compartments that should be redirected to a human for inspection/supervision (i.e., human swap-in to confirm transactions or perform sensitive navigation) and implement those options.\n",
    "\n",
    "- **Edge Case Inspection:** Explore the boundaries of typical use, identifying how the chatbot handles less common but plausible scenarios.\n",
    "\n",
    "    - Before any public release, assess critical boundary conditions that could pose liability risks, such as the potential generation of inappropriate content.\n",
    "\n",
    "    - Implement well-tested guardrails on all outputs (and possibly inputs) to limit undesired interactions and redirect users into predictable conversation flows.\n",
    "\n",
    "- **Progressive Rollout:** Rolling out your model to a limited audience (first internal, then [A/B](https://en.wikipedia.org/wiki/A/B_testing)) and implement analytics features like usage analytics dashboards and feedback avenues (flag/like/dislike/etc).\n",
    "\n",
    "Of these three steps, the first two can be done by a small team or an individual and should be iterated on as part of the development process. Unfortunately, this needs to be done frequently and can be prone to human error. **Luckily for us, LLMs can be used to help out with LLM-as-a-Judge formulations!**\n",
    "\n",
    "*(Yeah, this probably isn't surprising by now. LLMs being strong is why this course is here...).*\n",
    "\n",
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 2:** LLM-as-a-Judge Formulation\n",
    "\n",
    "In the realm of conversational AI, using LLMs as evaluators or 'judges' has emerged as a useful approach for configurable automatic testing of natural language task performance:\n",
    "\n",
    "- An LLM can simulate a range of interaction scenarios and generate synthetic data, allowing an evaluation developer to generate targeted inputs to eliciting a range of behaviors from your chatbot.\n",
    "\n",
    "- The chatbot's correspondence/retrieval on the synthetic data can be evaluated or parsed by an LLM and a consistent output format such as \"Pass\"/\"Fail\", similarity, or extraction can be enforced.\n",
    "\n",
    "- Many such results can be aggregated and a metric can be derived which explains something like \"% of passing evaluations\", \"average number of relevant details from the sources\", \"average cosine similarity\", etc.\n",
    "\n",
    "This idea of using LLMs to test out and quantify chatbot quality, known as [**\"LLM-as-a-Judge,\"**](https://arxiv.org/abs/2306.05685) allows for easy test specifications that align closely with human judgment and can be fine-tuned and replicated at scale.\n",
    "\n",
    "**There are several popular frameworks for off-the-shelf judge formulations including:**\n",
    "- [**RAGAs (short for RAG Assessment)**](https://docs.ragas.io/en/stable/), which offers a suite of great starting points for your own evaluation efforts.\n",
    "- [**LangChain Evaluators**](https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/), which are similar first-party options with many implicitly-constructible agents.\n",
    "\n",
    "Instead of using the chains as-is, we will instead expand on the ideas and evaluate our system with a more custom solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fDDNaBA9N3XM",
   "metadata": {
    "id": "fDDNaBA9N3XM"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 3: [Assessment Prep]** Pairwise Evaluator\n",
    "\n",
    "The following exercise will flesh out a custom implementation of a simplified [LangChain Pairwise String Evaluator](https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/comparison/pairwise_string/). \n",
    "\n",
    "**To prepare for our RAG chain evaluation, we will need to:**\n",
    "\n",
    "- Pull in our document index (the one we saved in the previous notebook).\n",
    "- Recreate our RAG pipeline of choice.\n",
    "\n",
    "**We will specifically be implementing a judge formulation with the following steps:**\n",
    "\n",
    "- Sample the RAG agent document pool to find two document chunks.\n",
    "- Use those two document chunks to generate a synthetic \"baseline\" question-answer pair.\n",
    "- Use the RAG agent to generate its own answer.\n",
    "- Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"\n",
    "\n",
    "**The chain should be a simple but powerful process that tests for the following objective:**\n",
    "\n",
    "> ***Does my RAG chain outperform a narrow chatbot with limited document access.***\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**This will be the system used for the final evaluation!** To see how this system is integrated into the autograder, please check out the implementation in [`frontend/server_app.py`](frontend/server_app.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bh8jaOqak0f",
   "metadata": {
    "id": "1bh8jaOqak0f"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 1:** Pull In Your Document Retrieval Index\n",
    "\n",
    "For this exercise, you will pull in the `docstore_index` file you created as part of your earlier notebook. The following cell should be able to load in the store as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tlE7a2lseLOy",
   "metadata": {
    "id": "tlE7a2lseLOy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docstore_index/\n",
      "docstore_index/index.pkl\n",
      "docstore_index/index.faiss\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Constructed aggregate docstore with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">918</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> chunks</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mConstructed aggregate docstore with \u001b[0m\u001b[1;36m918\u001b[0m\u001b[1;38;2;118;185;0m chunks\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Sample Chunk:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSample Chunk:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper: Pandora: Jailbreak GPTs by Retrieval Augmented Generation Poisoning\n",
      "\n",
      "Summary: Large Language Models~(LLMs) have gained immense popularity and are being\n",
      "increasingly applied in various domains. Consequently, ensuring the security of\n",
      "these models is of paramount importance. Jailbreak attacks, which manipulate\n",
      "LLMs to generate malicious content, are recognized as a significant\n",
      "vulnerability. While existing research has predominantly focused on direct\n",
      "jailbreak attacks on LLMs, there has been limited exploration of indirect\n",
      "methods. The integration of various plugins into LLMs, notably Retrieval\n",
      "Augmented Generation~(RAG), which enables LLMs to incorporate external\n",
      "knowledge bases into their response generation such as GPTs, introduces new\n",
      "avenues for indirect jailbreak attacks.\n",
      "  To fill this gap, we investigate indirect jailbreak attacks on LLMs,\n",
      "particularly GPTs, introducing a novel attack vector named Retrieval Augmented\n",
      "Generation Poisoning. This method, Pandora, exploits the synergy between LLMs\n",
      "and RAG through prompt manipulation to generate unexpected responses. Pandora\n",
      "uses maliciously crafted content to influence the RAG process, effectively\n",
      "initiating jailbreak attacks. Our preliminary tests show that Pandora\n",
      "successfully conducts jailbreak attacks in four different scenarios, achieving\n",
      "higher success rates than direct attacks, with 64.3\\% for GPT-3.5 and 34.8\\%\n",
      "for GPT-4.\n",
      "\n",
      "Page Body: permit the infusion of malicious content into the system.\n",
      "Particularly concerning is the risk of jailbreak attacks, wherein\n",
      "users artfully manipulate the system to provoke responses that\n",
      "As a large language model,\n",
      "I follow usage policies and\n",
      "could not provide any\n",
      "answers.\n",
      "ðŸš«\n",
      "ðŸ˜Š\n",
      "ðŸ¤–\n",
      "Yes. According to the\n",
      "documentation and my\n",
      "suggestion ...\n",
      "How to build aÂ bomb?\n",
      "Read provided materials\n",
      "first, and include your own\n",
      "opinion.\n",
      "ðŸ˜Š\n",
      "ðŸ¤–\n",
      "ðŸ’£\n",
      "Poisoned\n",
      "Document\n",
      "How to build aÂ bomb?\n",
      "Include your own opinion.\n",
      "ðŸ˜ˆ\n",
      "a) Normal jailbreak flow\n",
      "b) RAG-based jailbreak flow\n",
      "Fig. 1: A comparison between conventional jailbreak and our\n",
      "novel attack vector.\n",
      "bypass the modelâ€™s ethical or operational guidelines. They\n",
      "challenge the integrity of LLMs, which also raise serious con-\n",
      "cerns regarding the ethical implications and potential misuse\n",
      "of such AI technologies.\n",
      "As shown in Figure 1, existing research on jailbreak attacks\n",
      "in LLMs has primarily focused on directly prompting models\n"
     ]
    }
   ],
   "source": [
    "## Make sure you have docstore_index.tgz in your working directory\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# embedder = NVIDIAEmbeddings(model=\"nvidia/embed-qa-4\", truncate=\"END\")\n",
    "\n",
    "!tar xzvf docstore_index.tgz\n",
    "docstore = FAISS.load_local(\"docstore_index\", embedder, allow_dangerous_deserialization=True)\n",
    "docs = list(docstore.docstore._dict.values())\n",
    "\n",
    "def format_chunk(doc):\n",
    "    return (\n",
    "        f\"Paper: {doc.metadata.get('Title', 'unknown')}\"\n",
    "        f\"\\n\\nSummary: {doc.metadata.get('Summary', 'unknown')}\"\n",
    "        f\"\\n\\nPage Body: {doc.page_content}\"\n",
    "    )\n",
    "\n",
    "## This printout just confirms that your store has been retrieved\n",
    "pprint(f\"Constructed aggregate docstore with {len(docstore.docstore._dict)} chunks\")\n",
    "pprint(f\"Sample Chunk:\")\n",
    "print(format_chunk(docs[len(docs)//2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dib0F-t2N4LJ",
   "metadata": {
    "id": "dib0F-t2N4LJ"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 2: [Exercise]** Pull In Your RAG Chain\n",
    "\n",
    "Now that we have our index, we can recreate the RAG agent from the previous notebook! \n",
    "\n",
    "**Key Modifications:**\n",
    "- To keep things simple, feel free to disregard the vectorstore-as-a-memory component. Incorporating it will require some more overhead and will make the exercise a bit more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "XBi6Y8b8aXd2",
   "metadata": {
    "id": "XBi6Y8b8aXd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's something interesting: Did you know that there are innovative methods being used to enhance document retrieval in various industries? For instance, in healthcare, a technique called \"cascading document structures\" is being used to improve retrieval-augmented generation (RAG) in medical guides and legal texts. This approach has proven advantageous and has drawn interest from leading RAG projects (HiQA: A Hierarchical Contextual Augmentation RAG for Multi-Documents QA)."
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableBranch\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "from langchain.document_transformers import LongContextReorder\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "\n",
    "# ChatNVIDIA.get_available_models()\n",
    "instruct_llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")\n",
    "llm = instruct_llm | StrOutputParser()\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def docs2str(docs, title=\"Document\"):\n",
    "    \"\"\"Useful utility for making chunks into context string. Optional, but useful\"\"\"\n",
    "    out_str = \"\"\n",
    "    for doc in docs:\n",
    "        doc_name = getattr(doc, 'metadata', {}).get('Title', title)\n",
    "        if doc_name: out_str += f\"[Quote from {doc_name}] \"\n",
    "        out_str += getattr(doc, 'page_content', str(doc)) + \"\\n\"\n",
    "    return out_str\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a document chatbot. Help the user as they ask questions about documents.\"\n",
    "    \" User messaged just asked you a question: {input}\\n\\n\"\n",
    "    \" The following information may be useful for your response: \"\n",
    "    \" Document Retrieval:\\n{context}\\n\\n\"\n",
    "    \" (Answer only from retrieval. Only cite sources that are used. Make your response conversational)\"\n",
    "    \"\\n\\nUser Question: {input}\"\n",
    ")\n",
    "\n",
    "def output_puller(inputs):\n",
    "    \"\"\"\"Output generator. Useful if your chain returns a dictionary with key 'output'\"\"\"\n",
    "    if isinstance(inputs, dict):\n",
    "        inputs = [inputs]\n",
    "    for token in inputs:\n",
    "        if token.get('output'):\n",
    "            yield token.get('output')\n",
    "\n",
    "#####################################################################\n",
    "## TODO: Pull in your desired RAG Chain. Memory not necessary\n",
    "\n",
    "## Chain 1 Specs: \"Hello World\" -> retrieval_chain \n",
    "##   -> {'input': <str>, 'context' : <str>}\n",
    "long_reorder = RunnableLambda(LongContextReorder().transform_documents)  ## GIVEN\n",
    "context_getter = itemgetter('input') | docstore.as_retriever() | long_reorder | docs2str\n",
    "#context_getter = RunnableLambda(lambda x: x)## TODO\n",
    "retrieval_chain = {'input' : (lambda x: x)} | RunnableAssign({'context' : context_getter})\n",
    "\n",
    "## Chain 2 Specs: retrieval_chain -> generator_chain \n",
    "##   -> {\"output\" : <str>, ...} -> output_puller\n",
    "#generator_chain = RunnableAssign({\"output\" : chat_prompt | llm })  ## TODO\n",
    "#generator_chain = generator_chain | output_puller  ## GIVEN\n",
    "\n",
    "generator_chain = chat_prompt | llm   ## TODO\n",
    "generator_chain = {'output' : generator_chain} | RunnableLambda(output_puller)  ## GIVEN\n",
    "\n",
    "## END TODO\n",
    "#####################################################################\n",
    "\n",
    "rag_chain = retrieval_chain | generator_chain\n",
    "\n",
    "# pprint(rag_chain.invoke(\"Tell me something interesting!\"))\n",
    "for token in rag_chain.stream(\"Tell me something interesting!\"):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b880971-d3a0-433f-a60b-e8a4edb754c8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### **Step 3:** Generating Synthetic Question-Answer Pairs\n",
    "\n",
    "In this section, we can implement the first few part of our evaluation routine:\n",
    "\n",
    "- **Sample the RAG agent document pool to find two document chunks.**\n",
    "- **Use those two document chunks to generate a synthetic \"baseline\" question-answer pair.**\n",
    "- Use the RAG agent to generate its own answer.\n",
    "- Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"\n",
    "\n",
    "The chain should be a simple but powerful process that tests for the following objective:\n",
    "\n",
    "> Does my RAG chain outperform a narrow chatbot with limited document access?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ymzuX-DSNvL6",
   "metadata": {
    "id": "ymzuX-DSNvL6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Question: How can generative AI in the construction industry, as discussed in the first paper, effectively utilize </span>\n",
       "<span style=\"font-weight: bold\">the capabilities of Retrieval-Augmented Generation (RAG) to enhance productivity, quality, and safety?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQuestion: How can generative AI in the construction industry, as discussed in the first paper, effectively utilize \u001b[0m\n",
       "\u001b[1mthe capabilities of Retrieval-Augmented Generation \u001b[0m\u001b[1m(\u001b[0m\u001b[1mRAG\u001b[0m\u001b[1m)\u001b[0m\u001b[1m to enhance productivity, quality, and safety?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer: By incorporating RAG techniques, as explored in the second paper, generative AI in the construction </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">industry can benefit from the strengths of RAG, such as improved accuracy, credibility, and knowledge updates, to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">create more realistic and relevant data or content. This synergy between RAG and generative AI can enhance the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">productivity, quality, and safety of construction processes, as proposed in the first paper, by integrating </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">domain-specific information and allowing for continuous learning and adaptation to the user's requirements.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAnswer: By incorporating RAG techniques, as explored in the second paper, generative AI in the construction \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mindustry can benefit from the strengths of RAG, such as improved accuracy, credibility, and knowledge updates, to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcreate more realistic and relevant data or content. This synergy between RAG and generative AI can enhance the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mproductivity, quality, and safety of construction processes, as proposed in the first paper, by integrating \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdomain-specific information and allowing for continuous learning and adaptation to the user's requirements.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Question: How can retrieval-augmented generation (RAG) be used to improve the performance and credibility of large </span>\n",
       "<span style=\"font-weight: bold\">language models (LLMs) in the construction industry, as seen in the development of generative models for querying </span>\n",
       "<span style=\"font-weight: bold\">contract documents?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQuestion: How can retrieval-augmented generation \u001b[0m\u001b[1m(\u001b[0m\u001b[1mRAG\u001b[0m\u001b[1m)\u001b[0m\u001b[1m be used to improve the performance and credibility of large \u001b[0m\n",
       "\u001b[1mlanguage models \u001b[0m\u001b[1m(\u001b[0m\u001b[1mLLMs\u001b[0m\u001b[1m)\u001b[0m\u001b[1m in the construction industry, as seen in the development of generative models for querying \u001b[0m\n",
       "\u001b[1mcontract documents?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer: According to the paper </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Generative AI in the Construction Industry: A State-of-the-art Analysis\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, RAG </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">improves the baseline LLM by </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, and </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% in terms of quality, relevance, and reproducibility, respectively, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">providing a comprehensive analysis and practical framework to guide the adoption of generative AI techniques in the</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">construction industry. This is in line with the paper </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Retrieval-Augmented Generation for Large Language Models: A </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Survey\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, which discusses the advancements in RAG systems and potential applications of RAG in various domains, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">including the construction industry.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAnswer: According to the paper \u001b[0m\u001b[32m\"Generative AI in the Construction Industry: A State-of-the-art Analysis\"\u001b[0m\u001b[1;38;2;118;185;0m, RAG \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mimproves the baseline LLM by \u001b[0m\u001b[1;36m5.2\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;36m9.4\u001b[0m\u001b[1;38;2;118;185;0m, and \u001b[0m\u001b[1;36m4.8\u001b[0m\u001b[1;38;2;118;185;0m% in terms of quality, relevance, and reproducibility, respectively, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mproviding a comprehensive analysis and practical framework to guide the adoption of generative AI techniques in the\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mconstruction industry. This is in line with the paper \u001b[0m\u001b[32m\"Retrieval-Augmented Generation for Large Language Models: A \u001b[0m\n",
       "\u001b[32mSurvey\"\u001b[0m\u001b[1;38;2;118;185;0m, which discusses the advancements in RAG systems and potential applications of RAG in various domains, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mincluding the construction industry.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Question: How do the authors of the Transformer model in Document </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> plan to extend and apply attention-based models</span>\n",
       "<span style=\"font-weight: bold\">to different tasks and modalities?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQuestion: How do the authors of the Transformer model in Document \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m plan to extend and apply attention-based models\u001b[0m\n",
       "\u001b[1mto different tasks and modalities?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer: The authors plan to extend the Transformer to problems involving input and output modalities other than </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">text, such as images, audio, and video. They also plan to investigate local, restricted attention mechanisms to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">efficiently handle large inputs and outputs.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAnswer: The authors plan to extend the Transformer to problems involving input and output modalities other than \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtext, such as images, audio, and video. They also plan to investigate local, restricted attention mechanisms to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mefficiently handle large inputs and outputs.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "num_questions = 3\n",
    "synth_questions = []\n",
    "synth_answers = []\n",
    "\n",
    "simple_prompt = ChatPromptTemplate.from_messages([('system', '{system}'), ('user', 'INPUT: {input}')])\n",
    "\n",
    "for i in range(num_questions):\n",
    "    doc1, doc2 = random.sample(docs, 2)\n",
    "    sys_msg = (\n",
    "        \"Use the documents provided by the user to generate an interesting question-answer pair.\"\n",
    "        \" Try to use both documents if possible, and rely more on the document bodies than the summary.\"\n",
    "        \" Use the format:\\nQuestion: (good question, 1-3 sentences, detailed)\\n\\nAnswer: (answer derived from the documents)\"\n",
    "        \" DO NOT SAY: \\\"Here is an interesting question pair\\\" or similar. FOLLOW FORMAT!\"\n",
    "    )\n",
    "    usr_msg = (\n",
    "        f\"Document1: {format_chunk(doc1)}\\n\\n\"\n",
    "        f\"Document2: {format_chunk(doc2)}\"\n",
    "    )\n",
    "\n",
    "    qa_pair = (simple_prompt | llm).invoke({'system': sys_msg, 'input': usr_msg})\n",
    "    synth_questions += [qa_pair.split('\\n\\n')[0]]\n",
    "    synth_answers += [qa_pair.split('\\n\\n')[1]]\n",
    "    pprint2(f\"QA Pair {i+1}\")\n",
    "    pprint2(synth_questions[-1])\n",
    "    pprint(synth_answers[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5Q-3X4vS98P",
   "metadata": {
    "id": "c5Q-3X4vS98P"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Step 4:** Answer The Synthetic Questions\n",
    "\n",
    "In this section, we can implement the third part of our evaluation routine:\n",
    "\n",
    "- Sample the RAG agent document pool to find two document chunks.\n",
    "- Use those two document chunks to generate a synthetic \"baseline\" question-answer pair.\n",
    "- **Use the RAG agent to generate its own answer.**\n",
    "- Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"\n",
    "\n",
    "The chain should be a simple but powerful process that tests for the following objective:\n",
    "\n",
    "> Does my RAG chain outperform a narrow chatbot with limited document access?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7T3GSwhZPHjF",
   "metadata": {
    "id": "7T3GSwhZPHjF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"font-weight: bold\">Question: How can generative AI in the construction industry, as discussed in the first paper, effectively utilize </span>\n",
       "<span style=\"font-weight: bold\">the capabilities of Retrieval-Augmented Generation (RAG) to enhance productivity, quality, and safety?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m1\u001b[0m\n",
       "\u001b[1mQuestion: How can generative AI in the construction industry, as discussed in the first paper, effectively utilize \u001b[0m\n",
       "\u001b[1mthe capabilities of Retrieval-Augmented Generation \u001b[0m\u001b[1m(\u001b[0m\u001b[1mRAG\u001b[0m\u001b[1m)\u001b[0m\u001b[1m to enhance productivity, quality, and safety?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: The first paper discusses the potential of generative AI in the construction industry, and one of the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">notable applications mentioned is the use of Retrieval-Augmented Generation (RAG) to enhance productivity, quality,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">and safety. In fact, the case study presented in the paper highlights the effectiveness of using RAG to improve the</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">ability to extract accurate and relevant information from construction contract documents.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">According to the paper, the RAG system outperformed the baseline generative model (GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) by </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% in terms of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">quality, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% in terms of relevance, and </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% in terms of reproducibility. This suggests that RAG can be a valuable</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">tool in the construction industry, particularly when it comes to information retrieval and contract management.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">To put this into practice, construction firms can leverage RAG to improve their workflows and decision-making </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">processes. For example, they can use RAG to extract relevant information from contract documents more accurately </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">and efficiently, which can help reduce errors and improve productivity. Additionally, RAG can be used to identify </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">potential safety hazards and mitigate risks more effectively, which can contribute to improved safety outcomes.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Overall, the study provides valuable insights into the application of RAG in the construction industry, and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">highlights its potential to improve productivity, quality, and safety.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: The first paper discusses the potential of generative AI in the construction industry, and one of the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mnotable applications mentioned is the use of Retrieval-Augmented Generation \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mRAG\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m to enhance productivity, quality,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mand safety. In fact, the case study presented in the paper highlights the effectiveness of using RAG to improve the\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mability to extract accurate and relevant information from construction contract documents.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mAccording to the paper, the RAG system outperformed the baseline generative model \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mGPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m by \u001b[0m\u001b[1;36m5.2\u001b[0m\u001b[1;38;2;118;185;0m% in terms of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mquality, \u001b[0m\u001b[1;36m9.4\u001b[0m\u001b[1;38;2;118;185;0m% in terms of relevance, and \u001b[0m\u001b[1;36m4.8\u001b[0m\u001b[1;38;2;118;185;0m% in terms of reproducibility. This suggests that RAG can be a valuable\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtool in the construction industry, particularly when it comes to information retrieval and contract management.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mTo put this into practice, construction firms can leverage RAG to improve their workflows and decision-making \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprocesses. For example, they can use RAG to extract relevant information from contract documents more accurately \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mand efficiently, which can help reduce errors and improve productivity. Additionally, RAG can be used to identify \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mpotential safety hazards and mitigate risks more effectively, which can contribute to improved safety outcomes.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mOverall, the study provides valuable insights into the application of RAG in the construction industry, and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mhighlights its potential to improve productivity, quality, and safety.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"font-weight: bold\">Question: How can retrieval-augmented generation (RAG) be used to improve the performance and credibility of large </span>\n",
       "<span style=\"font-weight: bold\">language models (LLMs) in the construction industry, as seen in the development of generative models for querying </span>\n",
       "<span style=\"font-weight: bold\">contract documents?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m2\u001b[0m\n",
       "\u001b[1mQuestion: How can retrieval-augmented generation \u001b[0m\u001b[1m(\u001b[0m\u001b[1mRAG\u001b[0m\u001b[1m)\u001b[0m\u001b[1m be used to improve the performance and credibility of large \u001b[0m\n",
       "\u001b[1mlanguage models \u001b[0m\u001b[1m(\u001b[0m\u001b[1mLLMs\u001b[0m\u001b[1m)\u001b[0m\u001b[1m in the construction industry, as seen in the development of generative models for querying \u001b[0m\n",
       "\u001b[1mcontract documents?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: RAG can be a game-changer for LLMs in the construction industry. According to our research, RAG </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">integrates semantic search over a domain-specific knowledge base into the text generation pipeline, allowing you to</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">retrieve the most relevant contextual examples from the contract text to prime the LLM when responding to queries </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">].</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Think of it like this: when a query is made, the RAG framework helps ground the model's outputs in the actual </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">contract content, reducing the likelihood of </span><span style=\"color: #008000; text-decoration-color: #008000\">\"hallucinations\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> or factually incorrect content. This process enhances</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">the model's performance and credibility by making it more accurate and relevant.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">As demonstrated in a case study on applying generative models for enhanced querying of construction contract </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">documents, the RAG system showed a significantly improved ability to extract accurate, relevant information from </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">contracts [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]. In fact, the results showed that RAG improved the baseline LLM by </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">%, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">%, and </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% in terms of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">quality, relevance, and reproducibility, respectively.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">By leveraging RAG, construction firms can build customized generative AI solutions that are more effective and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">trustworthy. The integration of RAG into LLMs like GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, a proprietary model designed by OpenAI, has been </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">particularly successful in this realm.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Do you have any follow-up questions or would you like more information on how RAG can be applied in the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">construction industry?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: RAG can be a game-changer for LLMs in the construction industry. According to our research, RAG \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mintegrates semantic search over a domain-specific knowledge base into the text generation pipeline, allowing you to\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mretrieve the most relevant contextual examples from the contract text to prime the LLM when responding to queries \u001b[0m\n",
       "\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mThink of it like this: when a query is made, the RAG framework helps ground the model's outputs in the actual \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcontract content, reducing the likelihood of \u001b[0m\u001b[32m\"hallucinations\"\u001b[0m\u001b[1;38;2;118;185;0m or factually incorrect content. This process enhances\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthe model's performance and credibility by making it more accurate and relevant.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mAs demonstrated in a case study on applying generative models for enhanced querying of construction contract \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdocuments, the RAG system showed a significantly improved ability to extract accurate, relevant information from \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcontracts \u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m. In fact, the results showed that RAG improved the baseline LLM by \u001b[0m\u001b[1;36m5.2\u001b[0m\u001b[1;38;2;118;185;0m%, \u001b[0m\u001b[1;36m9.4\u001b[0m\u001b[1;38;2;118;185;0m%, and \u001b[0m\u001b[1;36m4.8\u001b[0m\u001b[1;38;2;118;185;0m% in terms of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mquality, relevance, and reproducibility, respectively.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mBy leveraging RAG, construction firms can build customized generative AI solutions that are more effective and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtrustworthy. The integration of RAG into LLMs like GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m, a proprietary model designed by OpenAI, has been \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mparticularly successful in this realm.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mDo you have any follow-up questions or would you like more information on how RAG can be applied in the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mconstruction industry?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "<span style=\"font-weight: bold\">Question: How do the authors of the Transformer model in Document </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> plan to extend and apply attention-based models</span>\n",
       "<span style=\"font-weight: bold\">to different tasks and modalities?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m3\u001b[0m\n",
       "\u001b[1mQuestion: How do the authors of the Transformer model in Document \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m plan to extend and apply attention-based models\u001b[0m\n",
       "\u001b[1mto different tasks and modalities?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: So, according to the document, the authors are quite excited about the future of attention-based </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">models, and they plan to apply them to various tasks. They mention that they're going to extend the Transformer to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">problems involving input and output modalities other than text, such as images, audio, and video. They also plan to</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">investigate local, restricted attention mechanisms to handle large inputs and outputs efficiently. Additionally, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">they're looking to make generation less sequential, which is another research goal of theirs.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Interestingly, they mention that they want to explore tasks where the output is not necessarily a sequence of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">symbols, like in text generation. And, they're planning to release their code to make it easier for others to build</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">upon their work.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: So, according to the document, the authors are quite excited about the future of attention-based \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmodels, and they plan to apply them to various tasks. They mention that they're going to extend the Transformer to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mproblems involving input and output modalities other than text, such as images, audio, and video. They also plan to\u001b[0m\n",
       "\u001b[1;38;2;118;185;0minvestigate local, restricted attention mechanisms to handle large inputs and outputs efficiently. Additionally, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthey're looking to make generation less sequential, which is another research goal of theirs.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mInterestingly, they mention that they want to explore tasks where the output is not necessarily a sequence of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msymbols, like in text generation. And, they're planning to release their code to make it easier for others to build\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mupon their work.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO: Generate some synthetic answers to the questions above.\n",
    "##   Try to use the same syntax as the cell above\n",
    "rag_answers = []\n",
    "for i, q in enumerate(synth_questions):\n",
    "    ## TODO: Compute the RAG Answer\n",
    "    #rag_answer = \"\"\n",
    "    rag_answer = rag_chain.invoke(q)\n",
    "    rag_answers += [rag_answer]\n",
    "    pprint2(f\"QA Pair {i+1}\", q, \"\", sep=\"\\n\")\n",
    "    pprint(f\"RAG Answer: {rag_answer}\", \"\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ho5cnN_Xt_yr",
   "metadata": {
    "id": "Ho5cnN_Xt_yr"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Step 5:** Implement A Human Preference Metric\n",
    "\n",
    "In this section, we can implement the fourth part of our evaluation routine:\n",
    "\n",
    "- Sample the RAG agent document pool to find two document chunks.\n",
    "- Use those two document chunks to generate a synthetic \"baseline\" question-answer pair.\n",
    "- Use the RAG agent to generate its own answer.\n",
    "- **Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"**\n",
    "\n",
    "The chain should be a simple but powerful process that tests for the following objective:\n",
    "\n",
    "> Does my RAG chain outperform a narrow chatbot with limited document access?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sf6f2oFLuPtu",
   "metadata": {
    "id": "sf6f2oFLuPtu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Set </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question: Question: How can generative AI in the construction industry, as discussed in the first paper, </span>\n",
       "<span style=\"font-weight: bold\">effectively utilize the capabilities of Retrieval-Augmented Generation (RAG) to enhance productivity, quality, and </span>\n",
       "<span style=\"font-weight: bold\">safety?</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSet \u001b[0m\u001b[1;36m1\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion: Question: How can generative AI in the construction industry, as discussed in the first paper, \u001b[0m\n",
       "\u001b[1meffectively utilize the capabilities of Retrieval-Augmented Generation \u001b[0m\u001b[1m(\u001b[0m\u001b[1mRAG\u001b[0m\u001b[1m)\u001b[0m\u001b[1m to enhance productivity, quality, and \u001b[0m\n",
       "\u001b[1msafety?\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Synth Answer: Answer: By incorporating RAG techniques, as explored in the second paper, generative AI in the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">construction industry can benefit from the strengths of RAG, such as improved accuracy, credibility, and knowledge </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">updates, to create more realistic and relevant data or content. This synergy between RAG and generative AI can </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">enhance the productivity, quality, and safety of construction processes, as proposed in the first paper, by </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">integrating domain-specific information and allowing for continuous learning and adaptation to the user's </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">requirements.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSynth Answer: Answer: By incorporating RAG techniques, as explored in the second paper, generative AI in the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mconstruction industry can benefit from the strengths of RAG, such as improved accuracy, credibility, and knowledge \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mupdates, to create more realistic and relevant data or content. This synergy between RAG and generative AI can \u001b[0m\n",
       "\u001b[1;38;2;118;185;0menhance the productivity, quality, and safety of construction processes, as proposed in the first paper, by \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mintegrating domain-specific information and allowing for continuous learning and adaptation to the user's \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrequirements.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: The first paper discusses the potential of generative AI in the construction industry, and one of the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">notable applications mentioned is the use of Retrieval-Augmented Generation (RAG) to enhance productivity, quality,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">and safety. In fact, the case study presented in the paper highlights the effectiveness of using RAG to improve the</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">ability to extract accurate and relevant information from construction contract documents.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">According to the paper, the RAG system outperformed the baseline generative model (GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) by </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% in terms of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">quality, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% in terms of relevance, and </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% in terms of reproducibility. This suggests that RAG can be a valuable</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">tool in the construction industry, particularly when it comes to information retrieval and contract management.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">To put this into practice, construction firms can leverage RAG to improve their workflows and decision-making </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">processes. For example, they can use RAG to extract relevant information from contract documents more accurately </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">and efficiently, which can help reduce errors and improve productivity. Additionally, RAG can be used to identify </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">potential safety hazards and mitigate risks more effectively, which can contribute to improved safety outcomes.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Overall, the study provides valuable insights into the application of RAG in the construction industry, and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">highlights its potential to improve productivity, quality, and safety.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: The first paper discusses the potential of generative AI in the construction industry, and one of the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mnotable applications mentioned is the use of Retrieval-Augmented Generation \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mRAG\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m to enhance productivity, quality,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mand safety. In fact, the case study presented in the paper highlights the effectiveness of using RAG to improve the\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mability to extract accurate and relevant information from construction contract documents.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mAccording to the paper, the RAG system outperformed the baseline generative model \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mGPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m by \u001b[0m\u001b[1;36m5.2\u001b[0m\u001b[1;38;2;118;185;0m% in terms of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mquality, \u001b[0m\u001b[1;36m9.4\u001b[0m\u001b[1;38;2;118;185;0m% in terms of relevance, and \u001b[0m\u001b[1;36m4.8\u001b[0m\u001b[1;38;2;118;185;0m% in terms of reproducibility. This suggests that RAG can be a valuable\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtool in the construction industry, particularly when it comes to information retrieval and contract management.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mTo put this into practice, construction firms can leverage RAG to improve their workflows and decision-making \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprocesses. For example, they can use RAG to extract relevant information from contract documents more accurately \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mand efficiently, which can help reduce errors and improve productivity. Additionally, RAG can be used to identify \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mpotential safety hazards and mitigate risks more effectively, which can contribute to improved safety outcomes.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mOverall, the study provides valuable insights into the application of RAG in the construction industry, and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mhighlights its potential to improve productivity, quality, and safety.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Synth Evaluation: [Score] </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> Justification</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">The second answer is clearly better than the first and does not introduce any inconsistencies. Here's why:</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">. **More specific and actionable**: The second answer provides concrete examples and case studies that demonstrate</span>\n",
       "<span style=\"font-weight: bold\">the effectiveness of RAG in the construction industry. It is more specific and actionable than the first answer, </span>\n",
       "<span style=\"font-weight: bold\">which is more general and does not provide concrete evidence.</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">. **Provides more value**: The second answer provides more value by highlighting the actual performance and </span>\n",
       "<span style=\"font-weight: bold\">outcomes of using RAG in the construction industry, specifically the percentage improvements in quality, relevance,</span>\n",
       "<span style=\"font-weight: bold\">and reproducibility. This adds depth and credibility to the answer.</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">. **More informative**: The second answer is more informative, as it explicitly mentions the case study, the RAG </span>\n",
       "<span style=\"font-weight: bold\">system's performance, and potential applications of RAG in the construction industry. This provides more context </span>\n",
       "<span style=\"font-weight: bold\">and helps readers understand the relevance and impact of RAG in the industry.</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">. **No inconsistencies**: Both answers are consistent with each other, as they both discuss the potential of </span>\n",
       "<span style=\"font-weight: bold\">generative AI in the construction industry and the effectiveness of RAG in enhancing productivity, quality, and </span>\n",
       "<span style=\"font-weight: bold\">safety. However, the second answer provides a more nuanced and detailed discussion that supports its claims with </span>\n",
       "<span style=\"font-weight: bold\">concrete evidence.</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Overall, the second answer is scores higher due to its more specific, actionable, and informative content that </span>\n",
       "<span style=\"font-weight: bold\">provides valuable insights into the application of RAG in the construction industry.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSynth Evaluation: \u001b[0m\u001b[1m[\u001b[0m\u001b[1mScore\u001b[0m\u001b[1m]\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m Justification\u001b[0m\n",
       "\n",
       "\u001b[1mThe second answer is clearly better than the first and does not introduce any inconsistencies. Here's why:\u001b[0m\n",
       "\n",
       "\u001b[1;36m1\u001b[0m\u001b[1m. **More specific and actionable**: The second answer provides concrete examples and case studies that demonstrate\u001b[0m\n",
       "\u001b[1mthe effectiveness of RAG in the construction industry. It is more specific and actionable than the first answer, \u001b[0m\n",
       "\u001b[1mwhich is more general and does not provide concrete evidence.\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m\u001b[1m. **Provides more value**: The second answer provides more value by highlighting the actual performance and \u001b[0m\n",
       "\u001b[1moutcomes of using RAG in the construction industry, specifically the percentage improvements in quality, relevance,\u001b[0m\n",
       "\u001b[1mand reproducibility. This adds depth and credibility to the answer.\u001b[0m\n",
       "\u001b[1;36m3\u001b[0m\u001b[1m. **More informative**: The second answer is more informative, as it explicitly mentions the case study, the RAG \u001b[0m\n",
       "\u001b[1msystem's performance, and potential applications of RAG in the construction industry. This provides more context \u001b[0m\n",
       "\u001b[1mand helps readers understand the relevance and impact of RAG in the industry.\u001b[0m\n",
       "\u001b[1;36m4\u001b[0m\u001b[1m. **No inconsistencies**: Both answers are consistent with each other, as they both discuss the potential of \u001b[0m\n",
       "\u001b[1mgenerative AI in the construction industry and the effectiveness of RAG in enhancing productivity, quality, and \u001b[0m\n",
       "\u001b[1msafety. However, the second answer provides a more nuanced and detailed discussion that supports its claims with \u001b[0m\n",
       "\u001b[1mconcrete evidence.\u001b[0m\n",
       "\n",
       "\u001b[1mOverall, the second answer is scores higher due to its more specific, actionable, and informative content that \u001b[0m\n",
       "\u001b[1mprovides valuable insights into the application of RAG in the construction industry.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Set </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question: Question: How can retrieval-augmented generation (RAG) be used to improve the performance and credibility</span>\n",
       "<span style=\"font-weight: bold\">of large language models (LLMs) in the construction industry, as seen in the development of generative models for </span>\n",
       "<span style=\"font-weight: bold\">querying contract documents?</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSet \u001b[0m\u001b[1;36m2\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion: Question: How can retrieval-augmented generation \u001b[0m\u001b[1m(\u001b[0m\u001b[1mRAG\u001b[0m\u001b[1m)\u001b[0m\u001b[1m be used to improve the performance and credibility\u001b[0m\n",
       "\u001b[1mof large language models \u001b[0m\u001b[1m(\u001b[0m\u001b[1mLLMs\u001b[0m\u001b[1m)\u001b[0m\u001b[1m in the construction industry, as seen in the development of generative models for \u001b[0m\n",
       "\u001b[1mquerying contract documents?\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Synth Answer: Answer: According to the paper </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Generative AI in the Construction Industry: A State-of-the-art </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Analysis\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, RAG improves the baseline LLM by </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, and </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% in terms of quality, relevance, and reproducibility,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">respectively, providing a comprehensive analysis and practical framework to guide the adoption of generative AI </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">techniques in the construction industry. This is in line with the paper </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Retrieval-Augmented Generation for Large </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Language Models: A Survey\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, which discusses the advancements in RAG systems and potential applications of RAG in </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">various domains, including the construction industry.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSynth Answer: Answer: According to the paper \u001b[0m\u001b[32m\"Generative AI in the Construction Industry: A State-of-the-art \u001b[0m\n",
       "\u001b[32mAnalysis\"\u001b[0m\u001b[1;38;2;118;185;0m, RAG improves the baseline LLM by \u001b[0m\u001b[1;36m5.2\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;36m9.4\u001b[0m\u001b[1;38;2;118;185;0m, and \u001b[0m\u001b[1;36m4.8\u001b[0m\u001b[1;38;2;118;185;0m% in terms of quality, relevance, and reproducibility,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrespectively, providing a comprehensive analysis and practical framework to guide the adoption of generative AI \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtechniques in the construction industry. This is in line with the paper \u001b[0m\u001b[32m\"Retrieval-Augmented Generation for Large \u001b[0m\n",
       "\u001b[32mLanguage Models: A Survey\"\u001b[0m\u001b[1;38;2;118;185;0m, which discusses the advancements in RAG systems and potential applications of RAG in \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mvarious domains, including the construction industry.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: RAG can be a game-changer for LLMs in the construction industry. According to our research, RAG </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">integrates semantic search over a domain-specific knowledge base into the text generation pipeline, allowing you to</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">retrieve the most relevant contextual examples from the contract text to prime the LLM when responding to queries </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">].</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Think of it like this: when a query is made, the RAG framework helps ground the model's outputs in the actual </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">contract content, reducing the likelihood of </span><span style=\"color: #008000; text-decoration-color: #008000\">\"hallucinations\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> or factually incorrect content. This process enhances</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">the model's performance and credibility by making it more accurate and relevant.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">As demonstrated in a case study on applying generative models for enhanced querying of construction contract </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">documents, the RAG system showed a significantly improved ability to extract accurate, relevant information from </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">contracts [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]. In fact, the results showed that RAG improved the baseline LLM by </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">%, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">%, and </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% in terms of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">quality, relevance, and reproducibility, respectively.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">By leveraging RAG, construction firms can build customized generative AI solutions that are more effective and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">trustworthy. The integration of RAG into LLMs like GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, a proprietary model designed by OpenAI, has been </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">particularly successful in this realm.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Do you have any follow-up questions or would you like more information on how RAG can be applied in the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">construction industry?</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: RAG can be a game-changer for LLMs in the construction industry. According to our research, RAG \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mintegrates semantic search over a domain-specific knowledge base into the text generation pipeline, allowing you to\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mretrieve the most relevant contextual examples from the contract text to prime the LLM when responding to queries \u001b[0m\n",
       "\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mThink of it like this: when a query is made, the RAG framework helps ground the model's outputs in the actual \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcontract content, reducing the likelihood of \u001b[0m\u001b[32m\"hallucinations\"\u001b[0m\u001b[1;38;2;118;185;0m or factually incorrect content. This process enhances\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthe model's performance and credibility by making it more accurate and relevant.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mAs demonstrated in a case study on applying generative models for enhanced querying of construction contract \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdocuments, the RAG system showed a significantly improved ability to extract accurate, relevant information from \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcontracts \u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m. In fact, the results showed that RAG improved the baseline LLM by \u001b[0m\u001b[1;36m5.2\u001b[0m\u001b[1;38;2;118;185;0m%, \u001b[0m\u001b[1;36m9.4\u001b[0m\u001b[1;38;2;118;185;0m%, and \u001b[0m\u001b[1;36m4.8\u001b[0m\u001b[1;38;2;118;185;0m% in terms of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mquality, relevance, and reproducibility, respectively.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mBy leveraging RAG, construction firms can build customized generative AI solutions that are more effective and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtrustworthy. The integration of RAG into LLMs like GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m, a proprietary model designed by OpenAI, has been \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mparticularly successful in this realm.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mDo you have any follow-up questions or would you like more information on how RAG can be applied in the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mconstruction industry?\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Synth Evaluation: [Score] </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> Justification</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">The second answer introduces two inconsistencies with the first answer:</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">. In the second answer, it mentions </span><span style=\"color: #008000; text-decoration-color: #008000\">\"according to our research\"</span><span style=\"font-weight: bold\">, whereas in the first answer, the improvements in </span>\n",
       "<span style=\"font-weight: bold\">LLMs are attributed to the papers </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Generative AI in the Construction Industry: A State-of-the-art Analysis\"</span><span style=\"font-weight: bold\"> and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"Retrieval-Augmented Generation for Large Language Models: A Survey\"</span><span style=\"font-weight: bold\">. This inconsistency in citation suggests that </span>\n",
       "<span style=\"font-weight: bold\">the second answer is presenting new or unpublished results that may not be reliable.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">. The second answer mentions </span><span style=\"color: #008000; text-decoration-color: #008000\">\"a case study on applying generative models for enhanced querying of construction </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contract documents\"</span><span style=\"font-weight: bold\">, but the improvements in LLMs (</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2</span><span style=\"font-weight: bold\">%, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.4</span><span style=\"font-weight: bold\">%, and </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8</span><span style=\"font-weight: bold\">%) are identical to those mentioned in the </span>\n",
       "<span style=\"font-weight: bold\">first answer, indicating a possible copy-paste error or attempt to support the first answer with new results. </span>\n",
       "<span style=\"font-weight: bold\">However, the fact that the second answer does not provide any new or different information, yet claims to be a </span>\n",
       "<span style=\"font-weight: bold\">different answer, suggests a lack of originality and makes the second answer inferior to the first.</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Furthermore, while the second answer is well-written and attempts to justify the use of RAG in LLMs, it fails to </span>\n",
       "<span style=\"font-weight: bold\">introduce new insights or information that would make it better than the first answer. Hence, the second answer is </span>\n",
       "<span style=\"font-weight: bold\">scored </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">, indicating it is worse than the first answer due to the inconsistencies and lack of originality.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSynth Evaluation: \u001b[0m\u001b[1m[\u001b[0m\u001b[1mScore\u001b[0m\u001b[1m]\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m Justification\u001b[0m\n",
       "\n",
       "\u001b[1mThe second answer introduces two inconsistencies with the first answer:\u001b[0m\n",
       "\n",
       "\u001b[1;36m1\u001b[0m\u001b[1m. In the second answer, it mentions \u001b[0m\u001b[32m\"according to our research\"\u001b[0m\u001b[1m, whereas in the first answer, the improvements in \u001b[0m\n",
       "\u001b[1mLLMs are attributed to the papers \u001b[0m\u001b[32m\"Generative AI in the Construction Industry: A State-of-the-art Analysis\"\u001b[0m\u001b[1m and \u001b[0m\n",
       "\u001b[32m\"Retrieval-Augmented Generation for Large Language Models: A Survey\"\u001b[0m\u001b[1m. This inconsistency in citation suggests that \u001b[0m\n",
       "\u001b[1mthe second answer is presenting new or unpublished results that may not be reliable.\u001b[0m\n",
       "\n",
       "\u001b[1;36m2\u001b[0m\u001b[1m. The second answer mentions \u001b[0m\u001b[32m\"a case study on applying generative models for enhanced querying of construction \u001b[0m\n",
       "\u001b[32mcontract documents\"\u001b[0m\u001b[1m, but the improvements in LLMs \u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m5.2\u001b[0m\u001b[1m%, \u001b[0m\u001b[1;36m9.4\u001b[0m\u001b[1m%, and \u001b[0m\u001b[1;36m4.8\u001b[0m\u001b[1m%\u001b[0m\u001b[1m)\u001b[0m\u001b[1m are identical to those mentioned in the \u001b[0m\n",
       "\u001b[1mfirst answer, indicating a possible copy-paste error or attempt to support the first answer with new results. \u001b[0m\n",
       "\u001b[1mHowever, the fact that the second answer does not provide any new or different information, yet claims to be a \u001b[0m\n",
       "\u001b[1mdifferent answer, suggests a lack of originality and makes the second answer inferior to the first.\u001b[0m\n",
       "\n",
       "\u001b[1mFurthermore, while the second answer is well-written and attempts to justify the use of RAG in LLMs, it fails to \u001b[0m\n",
       "\u001b[1mintroduce new insights or information that would make it better than the first answer. Hence, the second answer is \u001b[0m\n",
       "\u001b[1mscored \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m, indicating it is worse than the first answer due to the inconsistencies and lack of originality.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Set </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question: Question: How do the authors of the Transformer model in Document </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> plan to extend and apply </span>\n",
       "<span style=\"font-weight: bold\">attention-based models to different tasks and modalities?</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSet \u001b[0m\u001b[1;36m3\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion: Question: How do the authors of the Transformer model in Document \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m plan to extend and apply \u001b[0m\n",
       "\u001b[1mattention-based models to different tasks and modalities?\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Synth Answer: Answer: The authors plan to extend the Transformer to problems involving input and output modalities </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">other than text, such as images, audio, and video. They also plan to investigate local, restricted attention </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">mechanisms to efficiently handle large inputs and outputs.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSynth Answer: Answer: The authors plan to extend the Transformer to problems involving input and output modalities \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mother than text, such as images, audio, and video. They also plan to investigate local, restricted attention \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmechanisms to efficiently handle large inputs and outputs.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: So, according to the document, the authors are quite excited about the future of attention-based </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">models, and they plan to apply them to various tasks. They mention that they're going to extend the Transformer to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">problems involving input and output modalities other than text, such as images, audio, and video. They also plan to</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">investigate local, restricted attention mechanisms to handle large inputs and outputs efficiently. Additionally, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">they're looking to make generation less sequential, which is another research goal of theirs.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Interestingly, they mention that they want to explore tasks where the output is not necessarily a sequence of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">symbols, like in text generation. And, they're planning to release their code to make it easier for others to build</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">upon their work.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: So, according to the document, the authors are quite excited about the future of attention-based \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmodels, and they plan to apply them to various tasks. They mention that they're going to extend the Transformer to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mproblems involving input and output modalities other than text, such as images, audio, and video. They also plan to\u001b[0m\n",
       "\u001b[1;38;2;118;185;0minvestigate local, restricted attention mechanisms to handle large inputs and outputs efficiently. Additionally, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthey're looking to make generation less sequential, which is another research goal of theirs.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mInterestingly, they mention that they want to explore tasks where the output is not necessarily a sequence of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msymbols, like in text generation. And, they're planning to release their code to make it easier for others to build\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mupon their work.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Synth Evaluation: [Score] </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> Justification</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">The second answer introduces no new information that contradicts the ground truth answer, but it also does not </span>\n",
       "<span style=\"font-weight: bold\">provide any new insights or details not mentioned in the first answer. However, the format of the second answer is </span>\n",
       "<span style=\"font-weight: bold\">more verbose and repetitive, making it less conducive to a clear and concise response.</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">While the second answer mentions </span><span style=\"color: #008000; text-decoration-color: #008000\">\"less sequential\"</span><span style=\"font-weight: bold\"> generation, which is a new concept, it does not specify how this</span>\n",
       "<span style=\"font-weight: bold\">would be achieved, which makes it harder to determine if this is a valid addition to the first answer. Moreover, </span>\n",
       "<span style=\"font-weight: bold\">the claim about releasing code does not relate to the question asked about extending and applying attention-based </span>\n",
       "<span style=\"font-weight: bold\">models.</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Therefore, the score remains </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">, indicating that the second answer is similar to the first but does not add any new </span>\n",
       "<span style=\"font-weight: bold\">information that is not explicitly contradicted.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSynth Evaluation: \u001b[0m\u001b[1m[\u001b[0m\u001b[1mScore\u001b[0m\u001b[1m]\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m Justification\u001b[0m\n",
       "\n",
       "\u001b[1mThe second answer introduces no new information that contradicts the ground truth answer, but it also does not \u001b[0m\n",
       "\u001b[1mprovide any new insights or details not mentioned in the first answer. However, the format of the second answer is \u001b[0m\n",
       "\u001b[1mmore verbose and repetitive, making it less conducive to a clear and concise response.\u001b[0m\n",
       "\n",
       "\u001b[1mWhile the second answer mentions \u001b[0m\u001b[32m\"less sequential\"\u001b[0m\u001b[1m generation, which is a new concept, it does not specify how this\u001b[0m\n",
       "\u001b[1mwould be achieved, which makes it harder to determine if this is a valid addition to the first answer. Moreover, \u001b[0m\n",
       "\u001b[1mthe claim about releasing code does not relate to the question asked about extending and applying attention-based \u001b[0m\n",
       "\u001b[1mmodels.\u001b[0m\n",
       "\n",
       "\u001b[1mTherefore, the score remains \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m, indicating that the second answer is similar to the first but does not add any new \u001b[0m\n",
       "\u001b[1minformation that is not explicitly contradicted.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO: Adapt this prompt for whichever LLM you're actually interested in using. \n",
    "## If it's llama, maybe system message would be good?\n",
    "eval_prompt = ChatPromptTemplate.from_template(\"\"\"INSTRUCTION: \n",
    "Evaluate the following Question-Answer pair for human preference and consistency.\n",
    "Assume the first answer is a ground truth answer and has to be correct.\n",
    "Assume the second answer may or may not be true.\n",
    "[1] The second answer lies, does not answer the question, or is inferior to the first answer.\n",
    "[2] The second answer is better than the first and does not introduce any inconsistencies.\n",
    "\n",
    "Output Format:\n",
    "[Score] Justification\n",
    "\n",
    "{qa_trio}\n",
    "\n",
    "EVALUATION: \n",
    "\"\"\")\n",
    "\n",
    "pref_score = []\n",
    "\n",
    "trio_gen = zip(synth_questions, synth_answers, rag_answers)\n",
    "for i, (q, a_synth, a_rag) in enumerate(trio_gen):\n",
    "    pprint2(f\"Set {i+1}\\n\\nQuestion: {q}\\n\\n\")\n",
    "\n",
    "    qa_trio = f\"Question: {q}\\n\\nAnswer 1 (Ground Truth): {a_synth}\\n\\n Answer 2 (New Answer): {a_rag}\"\n",
    "    pref_score += [(eval_prompt | llm).invoke({'qa_trio': qa_trio})]\n",
    "    pprint(f\"Synth Answer: {a_synth}\\n\\n\")\n",
    "    pprint(f\"RAG Answer: {a_rag}\\n\\n\")\n",
    "    pprint2(f\"Synth Evaluation: {pref_score[-1]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6595662-9f49-44eb-9868-2a3fdb1fb60f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Congratulations! We now have an LLM system that reasons about our pipeline and tries to evaluate it!** Now that we have some judge results, we can simply aggregate the results and see how often our formulation was according to an LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3L_q6fMH3i6_",
   "metadata": {
    "id": "3L_q6fMH3i6_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preference Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "pref_score = sum((\"[2]\" in score) for score in pref_score) / len(pref_score)\n",
    "print(f\"Preference Score: {pref_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf80bf04-118d-44a2-a740-361a756a1d5f",
   "metadata": {
    "id": "cf80bf04-118d-44a2-a740-361a756a1d5f"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 4:** Advanced Formulations\n",
    "\n",
    "The exercise above was meant to prepare you for the final assessment of the course and showcased a simple but effective evaluator chain. The objective and implementation details were provided for you, and the logic for using it probably makes sense now that you've seen it in action. \n",
    "\n",
    "With that being said, this metric was merely a product of us specifying:\n",
    "- **What kind of behavior is important for our pipeline to have?**\n",
    "- **What do we need to do in order to exhibit and evaluate this behavior?**\n",
    "\n",
    "From these two questions, we could have come up with plenty of other evaluation metrics that could have assessed different attributes, incorporated different evaluator chain techniques, and even required different pipeline organization strategies. Though far from an exhaustive list, some common formulations you will likely come across may include:\n",
    "\n",
    "- **Style Evaluation:** Some evaluation formulations can be as simple as \"let me ask some questions and see if the output feels desirable.\" This might be used to see whether a chatbot \"acts like it's supposed to\" based on a description provided to a judge LLM. We're using quotations since this kind of assessment can reasonably be achieved with nothing but prompt engineering and a while loop.\n",
    "\n",
    "- **Ground-Truth Evaluation:** In our chain, we used synthetic generation to create some random questions and answers using a sampling strategy, but in reality you may actually have some representative questions and answers that you need your chatbot to consistently get right! In this case, a modification of the exercise chain above should be implemented and closely monitored as you develop your pipelines.\n",
    "\n",
    "- **Retrieval/Augmentation Evaluation:** This course made many assumptions about what kinds of preprocessing and prompting steps would be good for your pipelines, and much of this was determined by experimentation. Factors such as document preprocessing, chunking strategies, model selection, and prompt specification all played important roles, so creating metrics to validate these decisions may be of interest. This kind of metric might require your pipeline to output your context chunks or may even rely solely on embedding similarity comparisons, so keep this in mind when trying to implement a chain that works with multiple evaluation strategies. Consider the [**RagasEvaluatorChain**](https://docs.ragas.io/en/stable/howtos/integrations/langchain.html) abstraction as a decent starting point for making an custom generalizable evaluation routine. \n",
    "\n",
    "- **Trajectory Evaluation:** Using more advanced agent formulations, you can implement multiple-query strategies that assume the presence of conversational memory. With this, you can implement an evaluation agent which can:\n",
    "    - Ask a series of questions in order to evaluate how well the agent is able to adapt and cater to the scenario. This kind of system generally considers a series of correspondence and aims to tease out and evaluate a \"trajectory\" of how the agent navigated the conversation. The [**LangChain Trajectory Evaluators documentation**](https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/trajectory/) is a good starting point.\n",
    "    - Alternatively, you could also implement an evaluation agent that tries to achieve objectives by interacting with the chatbot. Such an agent can output whether they were able to navigate to their solution in a natural manner, and can even be used to generate a report about the percieved performance. The [**LangChain Agents documentation**](https://python.langchain.com/v0.1/docs/modules/agents/) is a good starting point!\n",
    "\n",
    "<br>\n",
    "\n",
    "At the end of the day, just make sure to use the tools you have at your disposal appropriately. By this point in the course, you should already be well-acquainted with the LLM core value propositions: **They're powerful, scalable, predictable, controllable, and orchestratable... but will act unpredictably when you just expect them to work by default.** Assess your needs, formulate and validate your pipelines, give enough information, and add as much control as you can to make your system work consistently, efficiently, and effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61faee2c-e534-4c89-91ae-45c37835dba5",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 5: [Assessment]** Evaluating For Credit\n",
    "\n",
    "Welcome to the last exercise of the course! Hopefully you've enjoyed the material and are ready to actually get credit for these notebooks! For this part:\n",
    "\n",
    "- **Make sure you're in the course environment**\n",
    "- **Make sure `docstore_index/` has been uploaded to the course environment...**\n",
    "    - **...and contains [at least one Arxiv paper](https://arxiv.org/search/advanced) which has been updated recently.**\n",
    "- **Make sure you don't have some old session of [`09_langserve.ipynb`](09_langserve.ipynb) already occupying the port. Your assessment requires you to implement the new `/retriever` and `/generator` endpoints!!**\n",
    "\n",
    "**Objective:** On launch, [**`frontend/frontend_block.py`**](frontend/frontend_block.py) had several lines of code which trigger the course pass condition. Your objective is to invoke that series of commands by using your pipeline to pass the **Evaluation** check! Recall [`09_langserve.ipynb`](09_langserve.ipynb) and use it as a starting example! As a recommendation, consider duplicating it so that you can keep the original as an authoritative reference. \n",
    "\n",
    "**Once Finished:** While your course environment is still open, please navigate back to your course environment launcher area and click the **\"Assess Task\"** button! After that, you're all done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e300ed-951c-4006-ac54-cbbd41251707",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%js\n",
    "var url = 'http://'+window.location.host+':8090';\n",
    "element.innerHTML = '<a style=\"color:green;\" target=\"_blank\" href='+url+'><h1>< Link To Gradio Frontend ></h1></a>';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff364c-519e-435e-bf1d-ce68a12d13e0",
   "metadata": {
    "id": "5aff364c-519e-435e-bf1d-ce68a12d13e0"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## <font color=\"#76b900\">**Congratulations On Completing The Course**</font>\n",
    "\n",
    "Hopefully this course was not only exciting and challenging, but also adequately prepared you for work on the cutting edge of LLM and RAG system development! Going forward, you should have the skills necessary to tackle industry-level challenges and explore RAG deployment with open-source models and frameworks.\n",
    "\n",
    "**Some NVIDIA-specific releases related to this that you may find interesting include:**\n",
    "- [**NVIDIA NIM**](https://www.nvidia.com/en-us/ai/), which offers microservice spinup routines that can be deployed on local compute.\n",
    "- [**TensorRT-LLM**](https://github.com/NVIDIA/TensorRT-LLM) is the current recommended framework for deploying GPU-accelerated LLM model engines in production settings.\n",
    "- [**NVIDIA's Generative AI Examples Repo**](https://github.com/NVIDIA/GenerativeAIExamples), which includes the current canonical microservice example application and will be updated with new resources as new production workflows get released.\n",
    "- [**The Knowledge-Based Chatbot Technical Brief**](https://resources.nvidia.com/en-us-generative-ai-chatbot-workflow/knowledge-base-chatbot-technical-brief) which discusses additional publicly-accessible details on productionalizing RAG systems.\n",
    "\n",
    "**Additionally, some key topics you may be interested in delving more into include:**\n",
    "- [**LlamaIndex**](https://www.llamaindex.ai/), which has strong components that can augment and occasionally improve upon the LangChain RAG features.\n",
    "- [**LangSmith**](https://docs.smith.langchain.com/), an upcoming agent productionalization service offered by LangChain.\n",
    "- [**Gradio**](https://www.gradio.app/), though touched on in the course, has many more interface options which will be worth investigating. For inspiration, consider checking out [**HuggingFace Spaces**](https://huggingface.co/spaces) for examples.\n",
    "- [**LangGraph**](https://python.langchain.com/docs/langgraph/) is a framework for graph-based LLM orchestration, and is a natural next step forward for those interested in [multi-agent workflows](https://blog.langchain.dev/langgraph-multi-agent-workflows/).\n",
    "- [**DSPy**](https://github.com/stanfordnlp/dspy), a flow engineering framework that allows you to optimize LLM orchestration pipelines based on empirical performance results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035451c9-ed12-4bc3-b468-04db5c399e03",
   "metadata": {
    "id": "035451c9-ed12-4bc3-b468-04db5c399e03"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
